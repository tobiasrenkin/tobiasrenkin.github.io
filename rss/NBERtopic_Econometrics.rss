<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>RSS for NBER topic Econometrics</title><link>a link</link><description>RSS for NBER topic Econometrics</description><language>en-US</language><lastBuildDate>Thu, 09 Dec 2021 19:47:53 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Researchers' Degrees-of-Flexibility and the Credibility of Difference-in-Differences Estimates: Evidence From the Pandemic Policy Evaluations</title><link>https://www.nber.org/papers/w29550</link><description><![CDATA[<b>December 2021</b> <p> The COVID-19 pandemic brought unprecedented policy responses and a large literature evaluating their impacts. This paper re-examines this literature and investigates the role of researchers' degrees-of-flexibility on the estimated effects of mobility-reducing policies on social-distancing behavior. We find that two-way fixed effects estimates are not robust to minor changes in usually-unexplored dimensions of the degree-of-flexibility space. While standard robustness tests based on the sequential addition of covariates are very stable, small changes in the outcome variable and its transformation lead to large and sometimes contradictory changes in the estimates, where the same policy can be found to significantly increase or decrease mobility. Yet, due to the large number of degrees-of-flexibility, one can focus on a set of results that appears stable, while ignoring problematic ones. We show that recently developed heterogeneity-robust difference-in-differences estimators only partially mitigate these issues, and discuss how a strategy of identifying the point at which a sequence of ever more-stringent robustness tests eventually fail could increase the credibility of policy evaluations.]]></description><author>Joakim A. Weill, Matthieu Stigler, Olivier Deschenes, Michael R. Springborn</author><guid isPermaLink="true">https://www.nber.org/papers/w29550</guid></item><item><title>Selection in Surveys</title><link>https://www.nber.org/papers/w29549</link><description><![CDATA[<b>December 2021</b> <p> We evaluate how nonresponse affects conclusions drawn from survey data and consider how researchers can reliably test and correct for nonresponse bias. To do so, we examine a survey on labor market conditions during the COVID-19 pandemic that used randomly assigned financial incentives to encourage participation. We link the survey data to administrative data sources, allowing us to observe a ground truth for participants and nonparticipants. We find evidence of large nonresponse bias, even after correcting for observable differences between participants and nonparticipants. We apply a range of existing methods that account for nonresponse bias due to unobserved differences, including worst-case bounds, bounds that incorporate monotonicity assumptions, and approaches based on parametric and nonparametric selection models. These methods produce bounds (or point estimates) that are either too wide to be useful or far from the ground truth. We show how these shortcomings can be addressed by modeling how nonparticipation can be both active (declining to participate) and passive (not seeing the survey invitation). The model makes use of variation from the randomly assigned financial incentives, as well as the timing of reminder emails. Applying the model to our data produces bounds (or point estimates) that are narrower and closer to the ground truth than the other methods.]]></description><author>Deniz Dutz, Ingrid Huitfeldt, Santiago Lacouture, Magne Mogstad, Alexander Torgovitsky, Winnie van Dijk</author><guid isPermaLink="true">https://www.nber.org/papers/w29549</guid></item><item><title>Real-Time Forecasting with a (Standard) Mixed-Frequency VAR During a Pandemic</title><link>https://www.nber.org/papers/w29535</link><description><![CDATA[<b>December 2021</b> <p> We resuscitated the mixed-frequency vector autoregression (MF-VAR) developed in Schorfheide and Song (2015, JBES) to generate macroeconomic forecasts for the U.S. during the COVID-19 pandemic in real time. The model combines eleven time series observed at two frequencies: quarterly and monthly. We deliberately did not modify the model specification in view of the COVID-19 outbreak, except for the exclusion of crisis observations from the estimation sample. We compare the MF-VAR forecasts to the median forecast from the Survey of Professional Forecasters (SPF). While the MF-VAR performed poorly during 2020:Q2, subsequent forecasts were at par with the SPF forecasts. We show that excluding a few months of extreme observations is a promising way of handling VAR estimation going forward, as an alternative of a sophisticated modeling of outliers.]]></description><author>Frank Schorfheide, Dongho Song</author><guid isPermaLink="true">https://www.nber.org/papers/w29535</guid></item><item><title>The Impact of Health and Education on Labor Force Participation in Aging Societies – Projections for the United States and Germany from a Dynamic Microsimulation</title><link>https://www.nber.org/papers/w29534</link><description><![CDATA[<b>December 2021</b> <p> Using a highly stylized dynamic microsimulation model, we project the labor force of the United States up to the year 2060 and contrast these projections with projections for Germany to assess differential effects on outcomes The projections are consistent with the U S Census Bureau’s and Eurostat’s demographic projections. Our modeling approach allows to show and quantify how policy changes the future size of the labor force, which we assess with a series of what-if scenarios.<br />
Both the US and Germany are expected to undergo demographic aging, but their demographic fundamentals differ starkly. This has strong implications for their labor force developments. According to our microsimulation, the US labor force will, despite population aging, increase by 16.2 percent in the age groups 15 to 74 (corresponding to 25.2 million workers) between 2020 and 2060, while Germany will experience a decline by 10.7 percent (4.4 million workers). In these baseline projections, improvements in the education structure will add about two million persons to the US labor force and about half a million persons to the German labor force by 2060.<br />
In the what-if scenarios, we examine the implications of improvements in the educational structure of the population and of policies which address the health impediments for labor force participation. Of the educational scenarios that we evaluate, increasing the number of persons who achieve more than lower education has the strongest positive impact on labor force participation, relative to the number of additional years of schooling implied by the various scenarios. Shifting people from intermediate to higher education levels also increases labor force participation in higher age groups, however, this is partially offset by lock in effects at younger ages.<br />
Our projections highlight that improvements in the labor market integration of people with health limitations provide a particularly promising avenue to increase labor force participation rates and thus help to address the challenges posed by demographic aging. If the health gap in participation rates in the United States were similar to that currently observed in Sweden, the labor force in 2060 would be larger by about 14.9 million persons.]]></description><author>René Böheim, Thomas Horvath, Thomas Leoni, Martin Spielauer</author><guid isPermaLink="true">https://www.nber.org/papers/w29534</guid></item><item><title>Incorporating Search and Sales Information in Demand Estimation</title><link>https://www.nber.org/papers/w29530</link><description><![CDATA[<b>December 2021</b> <p> We propose an approach to modeling and estimating discrete choice demand that allows for a large number of zero sale observations, rich unobserved heterogeneity, and endogenous prices. We do so by modeling small market sizes through Poisson arrivals. Each of these arriving consumers then solves a standard discrete choice problem. We present a Bayesian IV estimation approach that addresses sampling error in product shares and scales well to rich data environments. The data requirements are traditional market-level data and measures of consumer search intensity. After presenting simulation studies, we consider an empirical application of air travel demand where product-level sales are sparse. We find considerable variation in demand over time. Periods of peak demand feature both larger market sizes and consumers with higher willingness to pay. This amplifies cyclicality. However, observed frequent price and capacity adjustments offset some of this compounding effect.]]></description><author>Ali Hortaçsu, Olivia R. Natan, Hayden Parsley, Timothy Schwieg, Kevin R. Williams</author><guid isPermaLink="true">https://www.nber.org/papers/w29530</guid></item><item><title>Finite- and Large-Sample Inference for Ranks using Multinomial Data with an Application to Ranking Political Parties</title><link>https://www.nber.org/papers/w29519</link><description><![CDATA[<b>November 2021</b> <p> It is common to rank different categories by means of preferences that are revealed through data on choices. A prominent example is the ranking of political candidates or parties using the estimated share of support each one receives in surveys or polls about political attitudes. Since these rankings are computed using estimates of the share of support rather than the true share of support, there may be considerable uncertainty concerning the true ranking of the political candidates or parties. In this paper, we consider the problem of accounting for such uncertainty by constructing confidence sets for the rank of each category. We consider both the problem of constructing marginal confidence sets for the rank of a particular category as well as simultaneous confidence sets for the ranks of all categories. A distinguishing feature of our analysis is that we exploit the multinomial structure of the data to develop confidence sets that are valid in finite samples. We additionally develop confidence sets using the bootstrap that are valid only approximately in large samples. We use our methodology to rank political parties in Australia using data from the 2019 Australian Election Survey. We find that our finite-sample confidence sets are informative across the entire ranking of political parties, even in Australian territories with few survey respondents and/or with parties that are chosen by only a small share of the survey respondents. In contrast, the bootstrap-based confidence sets may sometimes be considerably less informative. These findings motivate us to compare these methods in an empirically-driven simulation study, in which we conclude that our finite-sample confidence sets often perform better than their large-sample, bootstrap-based counterparts, especially in settings that resemble our empirical application.]]></description><author>Sergei Bazylik, Magne Mogstad, Joseph P. Romano, Azeem Shaikh, Daniel Wilhelm</author><guid isPermaLink="true">https://www.nber.org/papers/w29519</guid></item><item><title>Organizational Structure and Pricing: Evidence from a Large U.S. Airline</title><link>https://www.nber.org/papers/w29508</link><description><![CDATA[<b>November 2021</b> <p> We study how organizational boundaries affect pricing decisions using comprehensive data from a large U.S. airline. We document that the firm's advanced pricing algorithm, utilizing inputs from different organizational teams, is subject to multiple biases. To quantify the impacts of these biases, we estimate a structural demand model using sales and search data. We recover the demand curves the firm believes it faces using forecasting data. In counterfactuals, we show that correcting biases introduced by organizational teams individually have little impact on market outcomes, but coordinating organizational outcomes leads to higher prices/revenues and increased dead-weight loss in the markets studied.]]></description><author>Ali Hortaçsu, Olivia R. Natan, Hayden Parsley, Timothy Schwieg, Kevin R. Williams</author><guid isPermaLink="true">https://www.nber.org/papers/w29508</guid></item><item><title>Modeling to Inform Economy-Wide Pandemic Policy: Bringing Epidemiologists and Economists Together</title><link>https://www.nber.org/papers/w29475</link><description><![CDATA[<b>November 2021</b> <p> Facing unprecedented uncertainty and drastic trade-offs between public health and other forms of human well-being, policy makers during the Covid-19 pandemic have sought the guidance of epidemiologists and economists. Unfortunately, while both groups of scientists use many of the same basic mathematical tools, the models they develop to inform policy tend to rely on different sets of assumptions and, thus, often lead to different policy conclusions. This divergence in policy recommendations can lead to uncertainty and confusion, opening the door to disinformation, distrust of institutions, and politicization of scientific facts. Unfortunately, to date, there have not been widespread efforts to build bridges and find consensus or even to clarify sources of differences across these fields, members of whom often continue to work within their traditional academic silos. In response to this “crisis of communication,” we convened a group of scholars from epidemiology, economics, and related fields (e.g., statistics, engineering, and health policy) to discuss approaches to modeling economy-wide pandemics. We summarize these conversations by providing a consensus view of disciplinary differences (including critiques) and working through a specific policy example. Thereafter, we chart a path forward for more effective synergy between disciplines, which we hope will lead to better policies as the current pandemic evolves and future pandemics emerge.]]></description><author>Michael E. Darden, David Dowdy, Lauren Gardner, Barton Hamilton, Karen Kopecky, Melissa Marx, Nicholas W. Papageorge, Daniel Polsky, Kimberly Powers, Elizabeth Stuart, Matthew Zahn</author><guid isPermaLink="true">https://www.nber.org/papers/w29475</guid></item><item><title>Salary History and Employer Demand: Evidence from a Two-Sided Audit</title><link>https://www.nber.org/papers/w29460</link><description><![CDATA[<b>November 2021</b> <p> We study how salary history disclosures affect employer demand by using a novel, two-sided field experiment featuring hundreds of recruiters reviewing over 2000 job applications. We randomize the presence of salary history questions as well as candidates' disclosures. We find that employers make negative inferences about non-disclosing candidates, and view salary history as a stronger signal about competing options than worker quality. Disclosures by men (and other highly-paid candidates) yield higher salary offers, however they are negative signals of value (net of salary), and thus yield fewer callbacks. Male wage premiums are regarded as a weaker signal of quality than other sources (such as the premiums from working at higher paying firms, or being well-paid compared to peers). Recruiters correctly anticipate that women are less likely to disclose salary history at any level, and punish women less than men for silence. In our simulation of bans, we find no evidence that bans affect the gender ratio of callback choices, but find large reductions in gender inequality in salary offers among candidates called back. However, salary offers are lower overall (especially for men). A theoretical framework shows how these effects may differ by key properties of labor markets.]]></description><author>Amanda Y. Agan, Bo Cowgill, Laura K. Gee</author><guid isPermaLink="true">https://www.nber.org/papers/w29460</guid></item><item><title>Some Children Left Behind: Variation in the Effects of an Educational Intervention</title><link>https://www.nber.org/papers/w29459</link><description><![CDATA[<b>November 2021</b> <p> We document substantial variation in the effects of a highly-effective literacy pro-gram in northern Uganda. The program increases test scores by 1.40 SDs on average, but standard statistical bounds show that the impact standard deviation exceeds 1.0SD. This implies that the variation in effects across our students is wider than the spread of mean effects across all randomized evaluations of developing country education interventions in the literature. This very effective program does indeed leave some students behind. At the same time, we do not learn much from our analyses that attempt to determine which students benefit more or less from the program. We reject rank preservation, and the weaker assumption of stochastic increasingness leaves wide bounds on quantile-specific average treatment effects. Neither conventional nor machine-learning approaches to estimating systematic heterogeneity capture more than a small fraction of the variation in impacts given our available candidate moderators.]]></description><author>Julie Buhl-Wiggers, Jason T. Kerwin, Juan S. Muñoz-Morales, Jeffrey A. Smith, Rebecca Thornton</author><guid isPermaLink="true">https://www.nber.org/papers/w29459</guid></item><item><title>Uncertainty and Change: Survey Evidence of Firms' Subjective Beliefs</title><link>https://www.nber.org/papers/w29430</link><description><![CDATA[<b>November 2021</b> <p> This paper studies how managers plan under uncertainty. In a new survey panel on German manufacturing firms, we show that uncertainty reflects change: Planning incorporates higher subjective uncertainty about future sales growth when the firm has just experienced unusual growth, and more so if the experience was negative. At the quarterly frequency, subjective uncertainty closely tracks conditional volatility of shocks: Both exhibit an asymmetric V-shaped relationship with past growth. In the cross section of firms, however, subjective uncertainty differs from conditional volatility: planning in successful firms—either large or fast-growing—reflects lower subjective uncertainty than in unsuccessful firms even when the size of the shocks is the same.]]></description><author>Ruediger Bachmann, Kai Carstensen, Stefan Lautenbacher, Martin Schneider</author><guid isPermaLink="true">https://www.nber.org/papers/w29430</guid></item><item><title>One Instrument to Rule Them All: The Bias and Coverage of Just-ID IV</title><link>https://www.nber.org/papers/w29417</link><description><![CDATA[<b>November 2021</b> <p> Two-stage least squares estimates in heavily over-identified instrumental variables (IV) models can be misleadingly close to the corresponding ordinary least squares (OLS) estimates when many instruments are weak. Just-identified (just-ID) IV estimates using a single instrument are also biased, but the importance of weak-instrument bias in just-ID IV applications remains contentious. We argue that in microeconometric applications, just-ID IV estimators can typically be treated as all but unbiased and that the usual inference strategies are likely to be adequate. The argument begins with contour plots for confidence interval coverage as a function of instrument strength and explanatory variable endogeneity. These show undercoverage in excess of 5% only for endogeneity beyond that seen even when IV and OLS estimates differ by an order of magnitude. Three widely cited microeconometric applications are used to explain why endogeneity is likely low enough for IV estimates to be reliable. We then show that an estimator that’s unbiased given a population first-stage sign restriction has bias exceeding that of IV when the restriction is imposed on the data. But screening on the sign of the estimated first stage is shown to halve the median bias of conventional IV without reducing coverage. To the extent that sign-screening is already part of empirical workflows, reported IV estimates enjoy the minimal bias of sign-screened just-ID IV.]]></description><author>Joshua Angrist, Michal Kolesár</author><guid isPermaLink="true">https://www.nber.org/papers/w29417</guid></item><item><title>Understanding Algorithmic Discrimination in Health Economics Through the Lens of Measurement Errors</title><link>https://www.nber.org/papers/w29413</link><description><![CDATA[<b>November 2021</b> <p> There is growing concern that the increasing use of machine learning and artificial intelligence-based systems may exacerbate health disparities through discrimination. We provide a hierarchical definition of discrimination consisting of algorithmic discrimination arising from predictive scores used for allocating resources and human discrimination arising from allocating resources by human decision-makers conditional on these predictive scores. We then offer an overarching statistical framework of algorithmic discrimination through the lens of measurement errors, which is familiar to the health economics audience. Specifically, we show that algorithmic discrimination exists when measurement errors exist in either the outcome or the predictors, and there is endogenous selection for participation in the observed data. The absence of any of these phenomena would eliminate algorithmic discrimination. We show that although equalized odds constraints can be employed as bias-mitigating strategies, such constraints may increase algorithmic discrimination when there is measurement error in the dependent variable.]]></description><author>Anirban Basu, Noah Hammarlund, Sara Khor, Aasthaa Bansal</author><guid isPermaLink="true">https://www.nber.org/papers/w29413</guid></item><item><title>Moment Inequalities and Partial Identification in Industrial Organization</title><link>https://www.nber.org/papers/w29409</link><description><![CDATA[<b>November 2021</b> <p> We review approaches to identification and inference on models in Industrial Organization with partial identification and/or moment inequalities. Often, such approaches are intentionally built directly on assumptions of optimizing behavior that are credible in Industrial Organization settings, while avoiding the use of strong modeling and measurement assumptions that may not be warranted. The result is an identified set for the object of interest, reflecting what the econometrician can learn from the data and assumptions. The chapter formally defines identification, reviews the assumptions underlying the identification argument, and provides examples of their use in Industrial Organization settings. We then discuss the corresponding statistical inference problem paying particular attention to practical implementation issues.]]></description><author>Brendan Kline, Ariel Pakes, Elie Tamer</author><guid isPermaLink="true">https://www.nber.org/papers/w29409</guid></item><item><title>It All Starts with Beliefs: Addressing the Roots of Educational Inequities by Shifting Parental Beliefs</title><link>https://www.nber.org/papers/w29394</link><description><![CDATA[<b>October 2021</b> <p> Socioeconomic inequalities in child development crystallize at early stages, with associated disparities in parental investment in children. A key to understanding the data patterns is to document the sources underlying the observed inequalities. We first show that there are dramatic differences in parental beliefs across socioeconomic backgrounds (SES), with parents of higher SES being more likely to believe that parental investments impact child development. We then use two field experiments targeted to low-SES families to explore the mutability of such beliefs and their link to parental investments. In both cases, we find that parental beliefs about child development are malleable. The less intensive version of the program based on educational videos changes parental beliefs, but fails to lastingly increase parental investments and child outcomes. By contrast, in the more intensive version of our program combining home visits and feedback, the augmented beliefs are associated with enriched parent-child interactions and improved vocabulary, math, and social-emotional skills for the children. Together, these results suggest that changing parental beliefs can be an important pathway to raising parental investments and reducing socioeconomic gaps in children’s skills, but that simple informational policies may not be sufficient.]]></description><author>John A. List, Julie Pernaudet, Dana Suskind</author><guid isPermaLink="true">https://www.nber.org/papers/w29394</guid></item><item><title>Interpreting the Will of the People: A Positive Analysis of Ordinal Preference Aggregation</title><link>https://www.nber.org/papers/w29389</link><description><![CDATA[<b>October 2021</b> <p> Collective decision making requires preference aggregation even if no ideal aggregation method exists (Arrow, 1950). We investigate how individuals think groups should aggregate members' ordinal preferences—that is, how they interpret "the will of the people." Our experiment elicits revealed attitudes toward ordinal preference aggregation and classifies subjects according to the rules they implicitly deploy. Majoritarianism is rare while rules that promote compromise are common. People evaluate relative sacrifice by inferring cardinal utility from ordinal ranks. Cluster analysis reveals that our classification encompasses all important aggregation rules. Aggregation methods exhibit stability across domains and across countries with divergent traditions.]]></description><author>Sandro Ambuehl, B. Douglas Bernheim</author><guid isPermaLink="true">https://www.nber.org/papers/w29389</guid></item><item><title>A (Dynamic) Investigation of Stereotypes, Belief-Updating, and Behavior</title><link>https://www.nber.org/papers/w29382</link><description><![CDATA[<b>October 2021</b> <p> Many decisions – such as what educational or career path to pursue – are dynamic in nature, with individuals receiving feedback at one point in time and making decisions later. Using a controlled experiment, with two sessions one week apart, we analyze the dynamic effects of feedback on beliefs about own performance and decision-making across two different domains (verbal skills and math). We find significant gender gaps in beliefs and choices before feedback: men are more optimistic about their performance and more willing to compete than women in both domains, but the gaps are significantly larger in math. Feedback significantly shifts individuals' beliefs and choices. Despite this, we see substantial persistence of gender gaps over time. This is particularly true among the set of individuals who receive negative feedback. We find that, holding fixed performance and decisions before feedback, women update their beliefs and choices more negatively than men do after bad news. Our results highlight the challenges involved in overcoming gender gaps in dynamic settings.]]></description><author>Katherine B. Coffman, Paola Ugalde Araya, Basit Zafar</author><guid isPermaLink="true">https://www.nber.org/papers/w29382</guid></item><item><title>Predicting the Oil Market</title><link>https://www.nber.org/papers/w29379</link><description><![CDATA[<b>October 2021</b> <p> We study the performance of many traditional and novel, text-based variables for in-sample and out-of-sample forecasting of oil spot, futures, and energy company stock returns, and changes in oil volatility, production, and inventories. After controlling for small-sample biases, we find evidence of in-sample predictability. Our text measures, derived using energy news articles, hold their own against traditional variables. While we cannot identify ex-ante rules for selecting successful out-of-sample forecasters, an analysis of all possible two-variable models reveals out-of-sample performance above that expected under random variation. Our findings provide new directions for identifying robust forecasting models for oil markets, and beyond.]]></description><author>Charles W. Calomiris, Harry Mamaysky, Nida Çakır Melek</author><guid isPermaLink="true">https://www.nber.org/papers/w29379</guid></item><item><title>Economic Data Engineering</title><link>https://www.nber.org/papers/w29378</link><description><![CDATA[<b>October 2021</b> <p> Economic data engineering deliberately designs novel forms of data to solve fundamental identification problems associated with economic models of choice. I outline three diverse applications: to the economics of information; to life-cycle employment, earnings, and spending; and to public policy analysis. In all three cases one and the same fundamental identification problem is driving data innovation: that of separately identifying appropriately rich preferences and beliefs. In addition to presenting these conceptually linked examples, I provide a general overview of the engineering process, outline important next steps, and highlight larger opportunities.]]></description><author>Andrew Caplin</author><guid isPermaLink="true">https://www.nber.org/papers/w29378</guid></item><item><title>The Anti-Poverty, Targeting, and Labor Supply Effects of the Proposed Child Tax Credit Expansion</title><link>https://www.nber.org/papers/w29366</link><description><![CDATA[<b>October 2021</b> <p> The proposed change under the American Families Plan (AFP) to the Tax Cuts and Jobs Act (TCJA) Child Tax Credit (CTC) would increase maximum benefit amounts to $3,000 or $3,600 per child (up from $2,000 per child) and make the full credit available to all low and middle-income families regardless of earnings or income. We estimate the anti-poverty, targeting, and labor supply effects of the expansion by linking survey data with administrative tax and government program data which form part of the Comprehensive Income Dataset (CID). Initially ignoring any behavioral responses, we estimate that the expansion of the CTC would reduce child poverty by 34% and deep child poverty by 39%. The expansion of the CTC would have a larger anti-poverty effect on children than any existing government program, though at a higher cost per child raised above the poverty line than any other means-tested program. Relatedly, the CTC expansion would allocate a smaller share of its total dollars to families at the bottom of the income distribution—as well as families with the lowest levels of long-term income, education, or health—than any existing means-tested program with the exception of housing assistance. We then simulate anti-poverty effects accounting for labor supply responses. By replacing the TCJA CTC (which contained substantial work incentives akin to the Earned Income Tax Credit) with a universal basic income-type benefit, the CTC expansion reduces the return to working at all by at least $2,000 per child for most workers with children. Relying on elasticity estimates consistent with mainstream simulation models and the academic literature, we estimate that this change in policy would lead 1.5 million workers (constituting 2.6% of all working parents) to exit the labor force. The decline in employment and the consequent earnings loss would mean that child poverty would only fall by 22% and deep child poverty would not fall at all with the CTC expansion.]]></description><author>Kevin Corinth, Bruce D. Meyer, Matthew Stadnicki, Derek Wu</author><guid isPermaLink="true">https://www.nber.org/papers/w29366</guid></item><item><title>“Beauty Too Rich for Use”*: Billionaires’ Assets and Attractiveness</title><link>https://www.nber.org/papers/w29361</link><description><![CDATA[<b>October 2021</b> <p> We examine how the net worth of billionaires relates to their looks, as rated by 16 people of different gender and ethnicity. Surprisingly, their financial assets are unrelated to their beauty; nor are they related to their educational attainment. As a group, however, billionaires are both more educated and better-looking than average for their age. Men, people who reside in Western countries, and those who inherited substantial wealth, are wealthier than other billionaires. The results do not arise from measurement error or nonrandom sample selectivity. They are consistent with econometric theory about the impact of truncating a sample to include observations only from the extreme tail of the dependent variable. The point is underscored by comparing estimates of earnings equations using all employees in the 2018 American Community Survey to those using a sample of the top 0.1 percent. The findings suggest the powerful role of luck within the extremes of the distributions of economic outcomes.]]></description><author>Daniel S. Hamermesh, Andrew Leigh</author><guid isPermaLink="true">https://www.nber.org/papers/w29361</guid></item><item><title>Probabilistic Prediction for Binary Treatment Choice: with Focus on Personalized Medicine</title><link>https://www.nber.org/papers/w29358</link><description><![CDATA[<b>October 2021</b> <p> This paper extends my research applying statistical decision theory to treatment choice with sample data, using maximum regret to evaluate the performance of treatment rules. The specific new contribution is to study as-if optimization using estimates of illness probabilities in clinical choice between surveillance and aggressive treatment. Beyond its specifics, the paper sends a broad message. Statisticians and computer scientists have addressed conditional prediction for decision making in indirect ways, the former applying classical statistical theory and the latter measuring prediction accuracy in test samples. Neither approach is satisfactory. Statistical decision theory provides a coherent, generally applicable methodology.]]></description><author>Charles F. Manski</author><guid isPermaLink="true">https://www.nber.org/papers/w29358</guid></item><item><title>Refining Set-Identification in VARs through Independence</title><link>https://www.nber.org/papers/w29316</link><description><![CDATA[<b>October 2021</b> <p> Identification in VARs has traditionally mainly relied on second moments. Some researchers have considered using higher moments as well, but there are concerns about the strength of the identification obtained in this way. In this paper, we propose refining existing identification schemes by augmenting sign restrictions with a requirement that rules out shocks whose higher moments significantly depart from independence. This approach does not assume that higher moments help with identification; it is robust to weak identification. In simulations we show that it controls coverage well, in contrast to approaches that assume that the higher moments deliver point-identification. However, it requires large sample sizes and/or considerable non-normality to reduce the width of confidence intervals by much. We consider some empirical applications.  We find that it can reject many possible rotations. The resulting confidence sets for impulse responses may be non-convex, corresponding to disjoint parts of the space of rotation  matrices. We show that in this case, augmenting sign and magnitude restrictions with an independence requirement can yield bigger gains.]]></description><author>Thorsten Drautzburg, Jonathan H. Wright</author><guid isPermaLink="true">https://www.nber.org/papers/w29316</guid></item><item><title>Task Allocation and On-the-job Training</title><link>https://www.nber.org/papers/w29312</link><description><![CDATA[<b>September 2021</b> <p> We study dynamic task allocation when providers' expertise evolves endogenously through training. We characterize optimal assignment protocols and compare them to discretionary procedures, where it is the clients who select their service providers. Our results indicate that welfare gains from centralization are greater when tasks arrive more rapidly, and when training technologies improve. Monitoring seniors' backlog of clients always increases welfare but may decrease training. Methodologically, we explore a matching setting with endogenous types, and illustrate useful adaptations of queueing theory techniques for such environments.]]></description><author>Mariagiovanna Baccara, SangMok Lee, Leeat Yariv</author><guid isPermaLink="true">https://www.nber.org/papers/w29312</guid></item><item><title>Foundations of Demand Estimation</title><link>https://www.nber.org/papers/w29305</link><description><![CDATA[<b>September 2021</b> <p> Demand elasticities and other features of demand are critical determinants of the answers to most positive and normative questions about market power or the functioning of markets in practice. As a result, reliable demand estimation is an essential input to many types of research in Industrial Organization and other fields of economics. This chapter presents a discussion of some foundational issues in demand estimation. We focus on the distinctive challenges of demand estimation and  strategies one can use  to overcome them. We cover core models, alternative data settings, common estimation approaches, the role and choice of instruments, and nonparametric identification.]]></description><author>Steven T. Berry, Philip A. Haile</author><guid isPermaLink="true">https://www.nber.org/papers/w29305</guid></item><item><title>Effect of the Jamaica Early Childhood Stimulation Intervention on Labor Market Outcomes at Age 31</title><link>https://www.nber.org/papers/w29292</link><description><![CDATA[<b>September 2021</b> <p> We report the labor market effects of the Jamaica Early Childhood Stimulation intervention at age 31. The study is a small-sample randomized early childhood education stimulation intervention targeting stunted children living in the poor neighborhoods of Kingston, Jamaica. Implemented in 1987-1989, treatment consisted of a two-year home-based intervention designed to improve nutrition and the quality of mother-child interactions to foster cognitive, language and psycho-social skills. The original sample is 127 stunted children between 9 and 24 months old. Our study is able to track and interview 75% of the original sample 30 years after the intervention, both still living in Jamaica and migrated abroad. We find large and statistically significant effects on income and schooling; the treatment group had 43% higher hourly wages and 37% higher earnings than the control group. This is a substantial increase over the treatment effect estimated for age 22 where we observed a 25% increase in earnings. The Jamaican Study is a rare case of a long-term follow up for an early childhood development (ECD) intervention implemented in a less-developed country. Our results confirm large economic returns to an early childhood intervention that targeted disadvantaged families living in poverty in the poor neighborhoods of Jamaica. The Jamaican intervention is being replicated around the world. Our analysis provides justification for expanding ECD interventions targeting disadvantaged children living in poor countries around the world.]]></description><author>Paul Gertler, James J. Heckman, Rodrigo Pinto, Susan M. Chang, Sally Grantham-McGregor, Christel Vermeersch, Susan Walker, Amika Wright</author><guid isPermaLink="true">https://www.nber.org/papers/w29292</guid></item><item><title>Dynamic Games in Empirical Industrial Organization</title><link>https://www.nber.org/papers/w29291</link><description><![CDATA[<b>September 2021</b> <p> This survey is organized around three main topics: models, econometrics, and empirical applications. Section 2 presents the theoretical framework, introduces the concept of Markov Perfect Nash Equilibrium, discusses existence and multiplicity, and describes the representation of this equilibrium in terms of conditional choice probabilities. We also discuss extensions of the basic framework, including models in continuous time, the concepts of oblivious equilibrium and experience-based equilibrium, and dynamic games where firms have non-equilibrium beliefs. In section 3, we first provide an overview of the types of data used in this literature, before turning to a discussion of identification issues and results, and estimation methods. We review different methods to deal with multiple equilibria and large state spaces. We also describe recent developments for estimating games in continuous time and incorporating serially correlated unobservables, and discuss the use of machine learning methods to solving and estimating dynamic games. Section 4 discusses empirical applications of dynamic games in IO. We start describing the first empirical applications in this literature during the early 2000s. Then, we review recent applications dealing with innovation, antitrust and mergers, dynamic pricing, regulation, product repositioning, advertising, uncertainty and investment, airline network competition, dynamic matching, and natural resources. We conclude with our view of the progress made in this literature and the remaining challenges.]]></description><author>Victor Aguirregabiria, Allan Collard-Wexler, Stephen P. Ryan</author><guid isPermaLink="true">https://www.nber.org/papers/w29291</guid></item><item><title>The Asymmetry in Responsible Investing Preferences</title><link>https://www.nber.org/papers/w29288</link><description><![CDATA[<b>September 2021</b> <p> We design an experiment to understand how social preferences affect investment decisions through stock allocations and probability assessments. The major preference channel is asymmetric in social outcomes – although negative and positive responsible investment (RI) externalities have the same magnitudes, negative externalities have greater impact on investment choices. The effect is persistent, but heterogenous. We also find asymmetries in belief formation and learning constitute a secondary channel. Overall, our results are consistent with important stylized empirical facts and the predictions of recent RI theories that social preferences lead to different investment choices, but our analyses also suggest important future modeling directions.]]></description><author>Jacquelyn Humphrey, Shimon Kogan, Jacob Sagi, Laura Starks</author><guid isPermaLink="true">https://www.nber.org/papers/w29288</guid></item><item><title>The Returns to College(s): Relative Value-Added and Match Effects in Higher Education</title><link>https://www.nber.org/papers/w29276</link><description><![CDATA[<b>September 2021</b> <p> Students who attend different colleges in the U.S. end up with vastly different economic outcomes. We study the role of relative value-added across colleges within student choice sets in producing these outcome disparities. Linking high school, college, and earnings registries spanning the state of Texas, we identify relative college value-added by comparing the outcomes of students who apply to and are admitted by the same set of institutions, as this approach strikingly balances observable student potential across college treatments and renders our extensive set of covariates irrelevant as controls. Methodologically, we develop a framework for identifying and interpreting value-added under varying assumptions about match effects and sorting gains. Empirically, we estimate a relatively tight, though non-degenerate, distribution of relative value-added across the wide diversity of Texas public universities. Selectivity poorly predicts value-added within student choice sets, with only a fleeting selectivity earnings premium fading to zero after a few years in the labor market. Non-peer college inputs like instructional spending more strongly predict value-added, especially conditional on selectivity. Colleges that boost BA completion, especially in STEM majors, also tend to boost earnings. Finally, we probe the potential for (mis)match effects by allowing value-added schedules to vary by student characteristics.]]></description><author>Jack Mountjoy, Brent R. Hickman</author><guid isPermaLink="true">https://www.nber.org/papers/w29276</guid></item><item><title>Memory and Probability</title><link>https://www.nber.org/papers/w29273</link><description><![CDATA[<b>September 2021</b> <p> People often estimate probabilities, such as the likelihood that an insurable risk will materialize or that an Irish person has red hair, by retrieving experiences from memory. We present a model of this process based on two established regularities of selective recall: similarity and interference. The model accounts for and reconciles a variety of conflicting empirical findings, such as overestimation of unlikely events when these are cued vs. neglect of non-cued ones, the availability heuristic, the representativeness heuristic, as well as over vs. underreaction to information in different situations. The model makes new predictions on how the content of a hypothesis (not just its objective probability) affects probability assessments by shaping the ease of recall. We experimentally evaluate these predictions and find strong experimental support.]]></description><author>Pedro Bordalo, John J. Conlon, Nicola Gennaioli, Spencer Yongwook Kwon, Andrei Shleifer</author><guid isPermaLink="true">https://www.nber.org/papers/w29273</guid></item><item><title>Fragile Algorithms and Fallible Decision-Makers: Lessons from the Justice System</title><link>https://www.nber.org/papers/w29267</link><description><![CDATA[<b>September 2021</b> <p> Algorithms (in some form) are already widely used in the criminal justice system.  We draw lessons from this experience for what is to come for the rest of society as machine learning diffuses. We find economists and other social scientists have a key role to play in shaping the impact of algorithms, in part through improving the tools used to build them.]]></description><author>Jens Ludwig, Sendhil Mullainathan</author><guid isPermaLink="true">https://www.nber.org/papers/w29267</guid></item><item><title>Experimental Evidence on Semi-structured Bargaining with Private Information</title><link>https://www.nber.org/papers/w29265</link><description><![CDATA[<b>September 2021</b> <p> We conduct a laboratory experiment to study a decentralized market where goods are differentiated and evaluations are private. We implement different semi-structured bargaining protocols based on deferred acceptance, and we compare their performance to the benchmark scenario of a sealed-bid auction. We show that bargaining dramatically improves efficiency, mainly to the benefit of players rather than the silent auctioneer. A protocol of unconstrained simultaneous bargaining performs best, doubling the proportion of deals relative to the benchmark. This is because participants seek to reveal information through a gradual bidding-up strategy that favors bargaining environments. Aggregate efficiency nonetheless suffers from the fact that buyers bargain harder than sellers, and that some players over-bargain to appropriate a larger share of the unknown surplus.]]></description><author>Margherita Comola, Marcel Fafchamps</author><guid isPermaLink="true">https://www.nber.org/papers/w29265</guid></item><item><title>Empirical Models of Demand and Supply in Differentiated Products Industries</title><link>https://www.nber.org/papers/w29257</link><description><![CDATA[<b>September 2021</b> <p> This is an invited chapter for the forthcoming Volume 4 of the Handbook of Industrial Organization. We present empirical models of demand and supply in differentiated products industries with an emphasis on the key ideas arising from the recent applied literature. We start with a discussion of the challenges in modeling and estimation of demand for  differentiated products, and focus on discrete choice characteristics-based demand models that address these challenges while allowing enough flexibility to capture realistic substitution patterns. Our discussion emphasizes how empirical strategies can leverage different features of data depending on the sources of variation that are commonly found in applied work. Moving to the supply-side, we show how demand estimates combined with a pricing model, can be used to recover markups and marginal costs. We also show how the model of pricing can be tested. We discuss a baseline Bertrand-Nash model of competitive pricing, and expand it to cover a) coordinated pricing, b) wholesale relationships, and c) bargaining. We end the chapter with extensions of the demand model, including dynamic and continuous demand.]]></description><author>Amit Gandhi, Aviv Nevo</author><guid isPermaLink="true">https://www.nber.org/papers/w29257</guid></item><item><title>Community Colleges and Upward Mobility</title><link>https://www.nber.org/papers/w29254</link><description><![CDATA[<b>September 2021</b> <p> Two-year community colleges enroll nearly half of all first-time undergraduates in the United States, but to ambiguous effect: low persistence rates and the potential for diverting students from 4-year institutions cast ambiguity over 2-year colleges' contributions to upward mobility. This paper develops a new instrumental variables approach to identifying causal effects along multiple treatment margins, and applies it to linked education and earnings registries to disentangle the net impacts of 2-year college access into two competing causal margins: significant value-added for 2-year entrants who otherwise would not have attended college, but negative impacts on students diverted from immediate 4-year entry.]]></description><author>Jack Mountjoy</author><guid isPermaLink="true">https://www.nber.org/papers/w29254</guid></item><item><title>Semiparametric Estimation of Treatment Effects in Randomized Experiments</title><link>https://www.nber.org/papers/w29242</link><description><![CDATA[<b>September 2021</b> <p> We develop new semiparametric methods for estimating treatment effects. We focus on a setting where the outcome distributions may be thick tailed, where treatment effects are small, where sample sizes are large and where assignment is completely random. This setting is of particular interest in recent experimentation in tech companies. We propose using parametric models for the treatment effects, as opposed to parametric models for the full outcome distributions. This leads to semiparametric models for the outcome distributions. We derive the semiparametric efficiency bound for this setting, and propose efficient estimators. In the case with a constant treatment effect one of the proposed estimators has an interesting interpretation as a weighted average of quantile treatment effects, with the weights proportional to (minus) the second derivative of the log of the density of the potential outcomes. Our analysis also results in an extension of Huber's model and trimmed mean to include asymmetry and a simplified condition on linear combinations of order statistics, which may be of independent interest.]]></description><author>Susan Athey, Peter J. Bickel, Aiyou Chen, Guido Imbens, Michael Pollmann</author><guid isPermaLink="true">https://www.nber.org/papers/w29242</guid></item><item><title>Measuring Market Expectations</title><link>https://www.nber.org/papers/w29232</link><description><![CDATA[<b>September 2021</b> <p> Asset prices are a valuable source of information about financial market participants' expectations about key macroeconomic variables. However, the presence of time-varying risk premia requires an adjustment of market prices to obtain the market's rational assessment of future price and policy developments. This paper reviews empirical approaches for recovering market-based expectations. It starts by laying out the two canonical modeling frameworks that form the backbone for estimating risk premia and highlights the proliferation of risk pricing factors that result in a wide range of different asset-price-based expectation measures. It then describes a key methodological innovation to evaluate the empirical plausibility of risk premium estimates and to identify the most accurate market-based expectation measure. The usefulness of this general approach is illustrated for price expectations in the global oil market. Then, the paper provides an overview of the body of empirical evidence for monetary policy and inflation expectations with a special emphasis on market-specific characteristics that complicate the quest for the best possible market-based expectation measure. Finally, it discusses a number of economic applications where market expectations play a key role for evaluating economic models, guiding policy analysis, and deriving shock measures.]]></description><author>Christiane Baumeister</author><guid isPermaLink="true">https://www.nber.org/papers/w29232</guid></item><item><title>How Well Does Bargaining Work in Consumer Markets? A Robust Bounds Approach</title><link>https://www.nber.org/papers/w29202</link><description><![CDATA[<b>August 2021</b> <p> This study provides a structural analysis of detailed, alternating-offer bargaining data from eBay, deriving bounds on buyers and sellers private value distributions using a range of assumptions on behavior. These assumptions range from very weak (assuming only that acceptance and rejection decisions are rational) to less weak (e.g., assuming that bargaining offers are weakly increasing in players' private values). We estimate the bounds and show what they imply for consumer negotiation behavior in theory and practice. For the median product, bargaining ends in impasses in 43% of negotiations even when the buyer values the good more than the seller.]]></description><author>Joachim Freyberger, Bradley Larsen</author><guid isPermaLink="true">https://www.nber.org/papers/w29202</guid></item><item><title>Using Household Rosters from Survey Data to Estimate All-cause Mortality during COVID in India</title><link>https://www.nber.org/papers/w29192</link><description><![CDATA[<b>August 2021</b> <p> Official statistics on deaths in India during the COVID pandemic are either incomplete or are reported with a delay.  To overcome this shortcoming, we estimate excess deaths in India using the household roster from a large panel data set, the Consumer Pyramids Household Survey, which reports attrition from death.  We address the problem that the exact timing of death is not reported in two ways, via a moving average and differencing monthly deaths.  We estimate roughly 4.5 million (95% CI: 2.8M to 6.2M) excess deaths over 16 months during the pandemic in India.  While we cannot demonstrate causality between COVID and excess deaths, the pattern of excess deaths is consistent with COVID-associated mortality.  Excess deaths peaked roughly during the two COVID waves in India; the age structure of excess deaths is right skewed relative to baseline, consistent with COVID infection fatality rates; and excess deaths are positively correlated with reported infections.  Finally, we find that the incidence of excess deaths was disproportionately among the highest tercile of income-earners and was negatively associated with district-level mobility.]]></description><author>Anup Malani, Sabareesh Ramachandran</author><guid isPermaLink="true">https://www.nber.org/papers/w29192</guid></item><item><title>Errors in Reporting and Imputation of Government Benefits and Their Implications</title><link>https://www.nber.org/papers/w29184</link><description><![CDATA[<b>August 2021</b> <p> We document the extent, nature, and consequences of survey errors in cash welfare and SNAP receipt in three major U.S. household surveys. We find high rates of misreporting, particularly failure to report receipt. The surveys inaccurately capture patterns of multiple program participation, even though there is little evidence of program confusion. Error rates are higher among imputed observations, which account for a large share of false positive errors. Many household characteristics have significant effects on both false positives and false negative errors. Error rates sharply differ by race, ethnicity, income and other household characteristics.  The errors greatly affect models of program receipt and estimated effects of income and race are noticeably biased. We examine error due to item non-response and imputation, as well as whether imputation improves estimates. Item non-respondents have higher receipt rates than the population conditional on covariates. The assumptions for consistent estimates in multivariate models fail both when excluding item non-respondents and when using the imputed values.  In binary choice models of program receipt, linked data estimates favor excluding item non-respondents rather than using imputed values. Biases are well predicted by the error patterns we document, helping researchers make informed decisions on whether to use imputed values.]]></description><author>Pablo A. Celhay, Bruce D. Meyer, Nikolas Mittag</author><guid isPermaLink="true">https://www.nber.org/papers/w29184</guid></item><item><title>Visualization, Identification, and Estimation in the Linear Panel Event-Study Design</title><link>https://www.nber.org/papers/w29170</link><description><![CDATA[<b>August 2021</b> <p> Linear panel models, and the "event-study plots" that often accompany them, are popular tools for learning about policy effects.  We discuss the construction of event-study plots and suggest ways to make them more informative. We examine the economic content of different possible identifying assumptions. We explore the performance of the corresponding estimators in simulations, highlighting that a given estimator can perform well or poorly depending on the economic environment. An accompanying Stata package, -xtevent-, facilitates adoption of our suggestions.]]></description><author>Simon Freyaldenhoven, Christian Hansen, Jorge Pérez Pérez, Jesse M. Shapiro</author><guid isPermaLink="true">https://www.nber.org/papers/w29170</guid></item><item><title>Shifting Punishment on Minorities: Experimental Evidence of Scapegoating</title><link>https://www.nber.org/papers/w29157</link><description><![CDATA[<b>August 2021</b> <p> This paper provides experimental evidence showing that members of a majority group systematically shift punishment on innocent members of an ethnic minority.  We develop a new incentivized task, the Punishing the Scapegoat Game, to measure how injustice affecting a member of one’s own group shapes punishment of an unrelated bystander (“a scapegoat”). We manipulate the ethnic identity of the scapegoats and study interactions between the majority group and the Roma minority in Slovakia. We find that when no harm is done, there is no evidence of discrimination against the ethnic minority. In contrast, when a member of one’s own group is harmed, the punishment ”passed” on innocent individuals more than doubles when they are from the minority, as compared to when they are from the dominant group. These results illuminate how individualized tensions can be transformed into a group conflict, dragging minorities into conflicts in a way that is completely unrelated to their behavior.]]></description><author>Michal Bauer, Jana Cahlíková, Julie Chytilová, Gérard Roland, Tomas Zelinsky</author><guid isPermaLink="true">https://www.nber.org/papers/w29157</guid></item><item><title>Do Lenders Still Discriminate? A Robust Approach for Assessing Differences in Menus</title><link>https://www.nber.org/papers/w29142</link><description><![CDATA[<b>August 2021</b> <p> Motivated by the assessment of racial discrimination in mortgage pricing, we introduce a new methodology for comparing the menus of options borrowers face based on their choices. First, we show how standard regression-based approaches for assessing discrimination in the menus context can lead to misleading and contradictory results. Second, we propose a new methodology that is robust these problems based on relatively weak economic assumptions. More specifically, we use pairwise dominance relationships in choices supplemented by restrictions on the range of plausible menus to define (1) a test statistic for equality in menus and (2) a difference in menus (DIM) metric for assessing whether one group of borrowers would prefer to switch to another group's menus. Our statistics are robust to arbitrary heterogeneity in borrower preferences across racial groups, are sharp in terms of identification, and can be efficiently computed using Optimal Transport methods. Third, we devise a new approach for inference on the value of Optimal Transport problems based on directional differentiation. Fourth, we use our methodology to estimate mortgage pricing differentials by race on a novel data set linking 2018--2019 Home Mortgage Disclosure Act (HMDA) data to Optimal Blue rate locks. We find robust evidence for mortgage pricing differentials by race, particularly among Conforming mortgage borrowers who are relatively creditworthy.]]></description><author>David Hao Zhang, Paul S. Willen</author><guid isPermaLink="true">https://www.nber.org/papers/w29142</guid></item><item><title>Exploring Spatial Price Relationships: The Case of African Swine Fever in China</title><link>https://www.nber.org/papers/w29141</link><description><![CDATA[<b>August 2021</b> <p> We use a temporary ban on inter-province shipping of live hogs induced by the 2018 outbreak of African Swine Fever (ASF) in China as a natural experiment to study spatial mechanisms behind the dynamics of market integration. With a unique dataset of weekly provincial hog prices, we employ a novel spatial network model to estimate the strength of price co-movement across provinces pre and post the ban. Results indicate that, in the highly integrated national market prior to the ban, longer geographical distances between two provinces did not weaken the strength of their price linkage. The ban broken down spatial integration. Longer distances became a significant obstacle to spatial price linkage in the post-ban periods, implying faster re-integration of hog prices between proximate provinces than remote ones. The negative effect of distance can be rationalized by the interplay between arbitrage opportunities and imperfect information. Our findings highlight information transparency as a key to market integration post shipping bans used to curb animal pandemics like ASF.]]></description><author>Michael S. Delgado, Meilin Ma, H. Holly Wang</author><guid isPermaLink="true">https://www.nber.org/papers/w29141</guid></item><item><title>Valid t-ratio Inference for IV</title><link>https://www.nber.org/papers/w29124</link><description><![CDATA[<b>August 2021</b> <p> In the single-IV model, researchers commonly rely on t-ratio-based inference, even though the literature has quantified its potentially severe large-sample distortions. Building on the approach for correcting inference of Stock and Yogo (2005), we introduce the tF critical value function, leading to a minimized standard error adjustment factor that is a smooth function of the first-stage F-statistic. Applying the correction to a sample of 61 AER papers leads to a 25 percent increase in standard errors, on average. tF confidence intervals have shorter expected length than those of Anderson and Rubin (1949), whenever both are bounded intervals.]]></description><author>David S. Lee, Justin McCrary, Marcelo J. Moreira, Jack R. Porter</author><guid isPermaLink="true">https://www.nber.org/papers/w29124</guid></item><item><title>Consistent Evidence on Duration Dependence of Price Changes</title><link>https://www.nber.org/papers/w29112</link><description><![CDATA[<b>August 2021</b> <p> We develop an estimator and tests of a discrete time mixed proportional hazard (MPH) model of duration with unobserved heterogeneity. We allow for competing risks, observable characteristics, and censoring, and we use linear GMM, making estimation and inference straightforward. With repeated spell data, our estimator is consistent and robust to the unknown shape of the frailty distribution. We apply our estimator to the duration of price spells in weekly store data from IRI. We find substantial unobserved heterogeneity, accounting for a large fraction of the decrease in the Kaplan-Meier hazard with elapsed duration. Still, we show that the estimated baseline hazard rate is decreasing and a homogeneous firm model can accurately capture the response of the economy to a monetary policy shock even if there is significant strategic complementarity in pricing. Using competing risks and spell-specific observable characteristics, we separately estimate the model for regular and temporary price changes and find that the MPH structure describes regular price changes better than temporary ones.]]></description><author>Fernando E. Alvarez, Katarína Borovičková, Robert Shimer</author><guid isPermaLink="true">https://www.nber.org/papers/w29112</guid></item></channel></rss>