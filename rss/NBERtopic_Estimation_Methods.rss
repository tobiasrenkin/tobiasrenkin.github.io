<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>RSS for NBER topic Estimation Methods</title><link>a link</link><description>RSS for NBER topic Estimation Methods</description><language>en-US</language><lastBuildDate>Fri, 03 Dec 2021 15:27:06 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Finite- and Large-Sample Inference for Ranks using Multinomial Data with an Application to Ranking Political Parties</title><link>https://www.nber.org/papers/w29519</link><description><![CDATA[<b>November 2021</b> <p> It is common to rank different categories by means of preferences that are revealed through data on choices. A prominent example is the ranking of political candidates or parties using the estimated share of support each one receives in surveys or polls about political attitudes. Since these rankings are computed using estimates of the share of support rather than the true share of support, there may be considerable uncertainty concerning the true ranking of the political candidates or parties. In this paper, we consider the problem of accounting for such uncertainty by constructing confidence sets for the rank of each category. We consider both the problem of constructing marginal confidence sets for the rank of a particular category as well as simultaneous confidence sets for the ranks of all categories. A distinguishing feature of our analysis is that we exploit the multinomial structure of the data to develop confidence sets that are valid in finite samples. We additionally develop confidence sets using the bootstrap that are valid only approximately in large samples. We use our methodology to rank political parties in Australia using data from the 2019 Australian Election Survey. We find that our finite-sample confidence sets are informative across the entire ranking of political parties, even in Australian territories with few survey respondents and/or with parties that are chosen by only a small share of the survey respondents. In contrast, the bootstrap-based confidence sets may sometimes be considerably less informative. These findings motivate us to compare these methods in an empirically-driven simulation study, in which we conclude that our finite-sample confidence sets often perform better than their large-sample, bootstrap-based counterparts, especially in settings that resemble our empirical application.]]></description><author>Sergei Bazylik, Magne Mogstad, Joseph P. Romano, Azeem Shaikh, Daniel Wilhelm</author><guid isPermaLink="true">https://www.nber.org/papers/w29519</guid></item><item><title>Organizational Structure and Pricing: Evidence from a Large U.S. Airline</title><link>https://www.nber.org/papers/w29508</link><description><![CDATA[<b>November 2021</b> <p> We study how organizational boundaries affect pricing decisions using comprehensive data from a large U.S. airline. We document that the firm's advanced pricing algorithm, utilizing inputs from different organizational teams, is subject to multiple biases. To quantify the impacts of these biases, we estimate a structural demand model using sales and search data. We recover the demand curves the firm believes it faces using forecasting data. In counterfactuals, we show that correcting biases introduced by organizational teams individually have little impact on market outcomes, but coordinating organizational outcomes leads to higher prices/revenues and increased dead-weight loss in the markets studied.]]></description><author>Ali Hortaçsu, Olivia R. Natan, Hayden Parsley, Timothy Schwieg, Kevin R. Williams</author><guid isPermaLink="true">https://www.nber.org/papers/w29508</guid></item><item><title>Some Children Left Behind: Variation in the Effects of an Educational Intervention</title><link>https://www.nber.org/papers/w29459</link><description><![CDATA[<b>November 2021</b> <p> We document substantial variation in the effects of a highly-effective literacy pro-gram in northern Uganda. The program increases test scores by 1.40 SDs on average, but standard statistical bounds show that the impact standard deviation exceeds 1.0SD. This implies that the variation in effects across our students is wider than the spread of mean effects across all randomized evaluations of developing country education interventions in the literature. This very effective program does indeed leave some students behind. At the same time, we do not learn much from our analyses that attempt to determine which students benefit more or less from the program. We reject rank preservation, and the weaker assumption of stochastic increasingness leaves wide bounds on quantile-specific average treatment effects. Neither conventional nor machine-learning approaches to estimating systematic heterogeneity capture more than a small fraction of the variation in impacts given our available candidate moderators.]]></description><author>Julie Buhl-Wiggers, Jason T. Kerwin, Juan S. Muñoz-Morales, Jeffrey A. Smith, Rebecca Thornton</author><guid isPermaLink="true">https://www.nber.org/papers/w29459</guid></item><item><title>One Instrument to Rule Them All: The Bias and Coverage of Just-ID IV</title><link>https://www.nber.org/papers/w29417</link><description><![CDATA[<b>November 2021</b> <p> Two-stage least squares estimates in heavily over-identified instrumental variables (IV) models can be misleadingly close to the corresponding ordinary least squares (OLS) estimates when many instruments are weak. Just-identified (just-ID) IV estimates using a single instrument are also biased, but the importance of weak-instrument bias in just-ID IV applications remains contentious. We argue that in microeconometric applications, just-ID IV estimators can typically be treated as all but unbiased and that the usual inference strategies are likely to be adequate. The argument begins with contour plots for confidence interval coverage as a function of instrument strength and explanatory variable endogeneity. These show undercoverage in excess of 5% only for endogeneity beyond that seen even when IV and OLS estimates differ by an order of magnitude. Three widely cited microeconometric applications are used to explain why endogeneity is likely low enough for IV estimates to be reliable. We then show that an estimator that’s unbiased given a population first-stage sign restriction has bias exceeding that of IV when the restriction is imposed on the data. But screening on the sign of the estimated first stage is shown to halve the median bias of conventional IV without reducing coverage. To the extent that sign-screening is already part of empirical workflows, reported IV estimates enjoy the minimal bias of sign-screened just-ID IV.]]></description><author>Joshua Angrist, Michal Kolesár</author><guid isPermaLink="true">https://www.nber.org/papers/w29417</guid></item><item><title>Understanding Algorithmic Discrimination in Health Economics Through the Lens of Measurement Errors</title><link>https://www.nber.org/papers/w29413</link><description><![CDATA[<b>November 2021</b> <p> There is growing concern that the increasing use of machine learning and artificial intelligence-based systems may exacerbate health disparities through discrimination. We provide a hierarchical definition of discrimination consisting of algorithmic discrimination arising from predictive scores used for allocating resources and human discrimination arising from allocating resources by human decision-makers conditional on these predictive scores. We then offer an overarching statistical framework of algorithmic discrimination through the lens of measurement errors, which is familiar to the health economics audience. Specifically, we show that algorithmic discrimination exists when measurement errors exist in either the outcome or the predictors, and there is endogenous selection for participation in the observed data. The absence of any of these phenomena would eliminate algorithmic discrimination. We show that although equalized odds constraints can be employed as bias-mitigating strategies, such constraints may increase algorithmic discrimination when there is measurement error in the dependent variable.]]></description><author>Anirban Basu, Noah Hammarlund, Sara Khor, Aasthaa Bansal</author><guid isPermaLink="true">https://www.nber.org/papers/w29413</guid></item><item><title>Moment Inequalities and Partial Identification in Industrial Organization</title><link>https://www.nber.org/papers/w29409</link><description><![CDATA[<b>November 2021</b> <p> We review approaches to identification and inference on models in Industrial Organization with partial identification and/or moment inequalities. Often, such approaches are intentionally built directly on assumptions of optimizing behavior that are credible in Industrial Organization settings, while avoiding the use of strong modeling and measurement assumptions that may not be warranted. The result is an identified set for the object of interest, reflecting what the econometrician can learn from the data and assumptions. The chapter formally defines identification, reviews the assumptions underlying the identification argument, and provides examples of their use in Industrial Organization settings. We then discuss the corresponding statistical inference problem paying particular attention to practical implementation issues.]]></description><author>Brendan Kline, Ariel Pakes, Elie Tamer</author><guid isPermaLink="true">https://www.nber.org/papers/w29409</guid></item><item><title>Predicting the Oil Market</title><link>https://www.nber.org/papers/w29379</link><description><![CDATA[<b>October 2021</b> <p> We study the performance of many traditional and novel, text-based variables for in-sample and out-of-sample forecasting of oil spot, futures, and energy company stock returns, and changes in oil volatility, production, and inventories. After controlling for small-sample biases, we find evidence of in-sample predictability. Our text measures, derived using energy news articles, hold their own against traditional variables. While we cannot identify ex-ante rules for selecting successful out-of-sample forecasters, an analysis of all possible two-variable models reveals out-of-sample performance above that expected under random variation. Our findings provide new directions for identifying robust forecasting models for oil markets, and beyond.]]></description><author>Charles W. Calomiris, Harry Mamaysky, Nida Çakır Melek</author><guid isPermaLink="true">https://www.nber.org/papers/w29379</guid></item><item><title>The Anti-Poverty, Targeting, and Labor Supply Effects of the Proposed Child Tax Credit Expansion</title><link>https://www.nber.org/papers/w29366</link><description><![CDATA[<b>October 2021</b> <p> The proposed change under the American Families Plan (AFP) to the Tax Cuts and Jobs Act (TCJA) Child Tax Credit (CTC) would increase maximum benefit amounts to $3,000 or $3,600 per child (up from $2,000 per child) and make the full credit available to all low and middle-income families regardless of earnings or income. We estimate the anti-poverty, targeting, and labor supply effects of the expansion by linking survey data with administrative tax and government program data which form part of the Comprehensive Income Dataset (CID). Initially ignoring any behavioral responses, we estimate that the expansion of the CTC would reduce child poverty by 34% and deep child poverty by 39%. The expansion of the CTC would have a larger anti-poverty effect on children than any existing government program, though at a higher cost per child raised above the poverty line than any other means-tested program. Relatedly, the CTC expansion would allocate a smaller share of its total dollars to families at the bottom of the income distribution—as well as families with the lowest levels of long-term income, education, or health—than any existing means-tested program with the exception of housing assistance. We then simulate anti-poverty effects accounting for labor supply responses. By replacing the TCJA CTC (which contained substantial work incentives akin to the Earned Income Tax Credit) with a universal basic income-type benefit, the CTC expansion reduces the return to working at all by at least $2,000 per child for most workers with children. Relying on elasticity estimates consistent with mainstream simulation models and the academic literature, we estimate that this change in policy would lead 1.5 million workers (constituting 2.6% of all working parents) to exit the labor force. The decline in employment and the consequent earnings loss would mean that child poverty would only fall by 22% and deep child poverty would not fall at all with the CTC expansion.]]></description><author>Kevin Corinth, Bruce D. Meyer, Matthew Stadnicki, Derek Wu</author><guid isPermaLink="true">https://www.nber.org/papers/w29366</guid></item><item><title>“Beauty Too Rich for Use”*: Billionaires’ Assets and Attractiveness</title><link>https://www.nber.org/papers/w29361</link><description><![CDATA[<b>October 2021</b> <p> We examine how the net worth of billionaires relates to their looks, as rated by 16 people of different gender and ethnicity. Surprisingly, their financial assets are unrelated to their beauty; nor are they related to their educational attainment. As a group, however, billionaires are both more educated and better-looking than average for their age. Men, people who reside in Western countries, and those who inherited substantial wealth, are wealthier than other billionaires. The results do not arise from measurement error or nonrandom sample selectivity. They are consistent with econometric theory about the impact of truncating a sample to include observations only from the extreme tail of the dependent variable. The point is underscored by comparing estimates of earnings equations using all employees in the 2018 American Community Survey to those using a sample of the top 0.1 percent. The findings suggest the powerful role of luck within the extremes of the distributions of economic outcomes.]]></description><author>Daniel S. Hamermesh, Andrew Leigh</author><guid isPermaLink="true">https://www.nber.org/papers/w29361</guid></item><item><title>Probabilistic Prediction for Binary Treatment Choice: with Focus on Personalized Medicine</title><link>https://www.nber.org/papers/w29358</link><description><![CDATA[<b>October 2021</b> <p> This paper extends my research applying statistical decision theory to treatment choice with sample data, using maximum regret to evaluate the performance of treatment rules. The specific new contribution is to study as-if optimization using estimates of illness probabilities in clinical choice between surveillance and aggressive treatment. Beyond its specifics, the paper sends a broad message. Statisticians and computer scientists have addressed conditional prediction for decision making in indirect ways, the former applying classical statistical theory and the latter measuring prediction accuracy in test samples. Neither approach is satisfactory. Statistical decision theory provides a coherent, generally applicable methodology.]]></description><author>Charles F. Manski</author><guid isPermaLink="true">https://www.nber.org/papers/w29358</guid></item><item><title>Refining Set-Identification in VARs through Independence</title><link>https://www.nber.org/papers/w29316</link><description><![CDATA[<b>October 2021</b> <p> Identification in VARs has traditionally mainly relied on second moments. Some researchers have considered using higher moments as well, but there are concerns about the strength of the identification obtained in this way. In this paper, we propose refining existing identification schemes by augmenting sign restrictions with a requirement that rules out shocks whose higher moments significantly depart from independence. This approach does not assume that higher moments help with identification; it is robust to weak identification. In simulations we show that it controls coverage well, in contrast to approaches that assume that the higher moments deliver point-identification. However, it requires large sample sizes and/or considerable non-normality to reduce the width of confidence intervals by much. We consider some empirical applications.  We find that it can reject many possible rotations. The resulting confidence sets for impulse responses may be non-convex, corresponding to disjoint parts of the space of rotation  matrices. We show that in this case, augmenting sign and magnitude restrictions with an independence requirement can yield bigger gains.]]></description><author>Thorsten Drautzburg, Jonathan H. Wright</author><guid isPermaLink="true">https://www.nber.org/papers/w29316</guid></item><item><title>Foundations of Demand Estimation</title><link>https://www.nber.org/papers/w29305</link><description><![CDATA[<b>September 2021</b> <p> Demand elasticities and other features of demand are critical determinants of the answers to most positive and normative questions about market power or the functioning of markets in practice. As a result, reliable demand estimation is an essential input to many types of research in Industrial Organization and other fields of economics. This chapter presents a discussion of some foundational issues in demand estimation. We focus on the distinctive challenges of demand estimation and  strategies one can use  to overcome them. We cover core models, alternative data settings, common estimation approaches, the role and choice of instruments, and nonparametric identification.]]></description><author>Steven T. Berry, Philip A. Haile</author><guid isPermaLink="true">https://www.nber.org/papers/w29305</guid></item><item><title>Effect of the Jamaica Early Childhood Stimulation Intervention on Labor Market Outcomes at Age 31</title><link>https://www.nber.org/papers/w29292</link><description><![CDATA[<b>September 2021</b> <p> We report the labor market effects of the Jamaica Early Childhood Stimulation intervention at age 31. The study is a small-sample randomized early childhood education stimulation intervention targeting stunted children living in the poor neighborhoods of Kingston, Jamaica. Implemented in 1987-1989, treatment consisted of a two-year home-based intervention designed to improve nutrition and the quality of mother-child interactions to foster cognitive, language and psycho-social skills. The original sample is 127 stunted children between 9 and 24 months old. Our study is able to track and interview 75% of the original sample 30 years after the intervention, both still living in Jamaica and migrated abroad. We find large and statistically significant effects on income and schooling; the treatment group had 43% higher hourly wages and 37% higher earnings than the control group. This is a substantial increase over the treatment effect estimated for age 22 where we observed a 25% increase in earnings. The Jamaican Study is a rare case of a long-term follow up for an early childhood development (ECD) intervention implemented in a less-developed country. Our results confirm large economic returns to an early childhood intervention that targeted disadvantaged families living in poverty in the poor neighborhoods of Jamaica. The Jamaican intervention is being replicated around the world. Our analysis provides justification for expanding ECD interventions targeting disadvantaged children living in poor countries around the world.]]></description><author>Paul Gertler, James J. Heckman, Rodrigo Pinto, Susan M. Chang, Sally Grantham-McGregor, Christel Vermeersch, Susan Walker, Amika Wright</author><guid isPermaLink="true">https://www.nber.org/papers/w29292</guid></item><item><title>The Returns to College(s): Relative Value-Added and Match Effects in Higher Education</title><link>https://www.nber.org/papers/w29276</link><description><![CDATA[<b>September 2021</b> <p> Students who attend different colleges in the U.S. end up with vastly different economic outcomes. We study the role of relative value-added across colleges within student choice sets in producing these outcome disparities. Linking high school, college, and earnings registries spanning the state of Texas, we identify relative college value-added by comparing the outcomes of students who apply to and are admitted by the same set of institutions, as this approach strikingly balances observable student potential across college treatments and renders our extensive set of covariates irrelevant as controls. Methodologically, we develop a framework for identifying and interpreting value-added under varying assumptions about match effects and sorting gains. Empirically, we estimate a relatively tight, though non-degenerate, distribution of relative value-added across the wide diversity of Texas public universities. Selectivity poorly predicts value-added within student choice sets, with only a fleeting selectivity earnings premium fading to zero after a few years in the labor market. Non-peer college inputs like instructional spending more strongly predict value-added, especially conditional on selectivity. Colleges that boost BA completion, especially in STEM majors, also tend to boost earnings. Finally, we probe the potential for (mis)match effects by allowing value-added schedules to vary by student characteristics.]]></description><author>Jack Mountjoy, Brent R. Hickman</author><guid isPermaLink="true">https://www.nber.org/papers/w29276</guid></item><item><title>Fragile Algorithms and Fallible Decision-Makers: Lessons from the Justice System</title><link>https://www.nber.org/papers/w29267</link><description><![CDATA[<b>September 2021</b> <p> Algorithms (in some form) are already widely used in the criminal justice system.  We draw lessons from this experience for what is to come for the rest of society as machine learning diffuses. We find economists and other social scientists have a key role to play in shaping the impact of algorithms, in part through improving the tools used to build them.]]></description><author>Jens Ludwig, Sendhil Mullainathan</author><guid isPermaLink="true">https://www.nber.org/papers/w29267</guid></item><item><title>Community Colleges and Upward Mobility</title><link>https://www.nber.org/papers/w29254</link><description><![CDATA[<b>September 2021</b> <p> Two-year community colleges enroll nearly half of all first-time undergraduates in the United States, but to ambiguous effect: low persistence rates and the potential for diverting students from 4-year institutions cast ambiguity over 2-year colleges' contributions to upward mobility. This paper develops a new instrumental variables approach to identifying causal effects along multiple treatment margins, and applies it to linked education and earnings registries to disentangle the net impacts of 2-year college access into two competing causal margins: significant value-added for 2-year entrants who otherwise would not have attended college, but negative impacts on students diverted from immediate 4-year entry.]]></description><author>Jack Mountjoy</author><guid isPermaLink="true">https://www.nber.org/papers/w29254</guid></item><item><title>Semiparametric Estimation of Treatment Effects in Randomized Experiments</title><link>https://www.nber.org/papers/w29242</link><description><![CDATA[<b>September 2021</b> <p> We develop new semiparametric methods for estimating treatment effects. We focus on a setting where the outcome distributions may be thick tailed, where treatment effects are small, where sample sizes are large and where assignment is completely random. This setting is of particular interest in recent experimentation in tech companies. We propose using parametric models for the treatment effects, as opposed to parametric models for the full outcome distributions. This leads to semiparametric models for the outcome distributions. We derive the semiparametric efficiency bound for this setting, and propose efficient estimators. In the case with a constant treatment effect one of the proposed estimators has an interesting interpretation as a weighted average of quantile treatment effects, with the weights proportional to (minus) the second derivative of the log of the density of the potential outcomes. Our analysis also results in an extension of Huber's model and trimmed mean to include asymmetry and a simplified condition on linear combinations of order statistics, which may be of independent interest.]]></description><author>Susan Athey, Peter J. Bickel, Aiyou Chen, Guido Imbens, Michael Pollmann</author><guid isPermaLink="true">https://www.nber.org/papers/w29242</guid></item><item><title>Measuring Market Expectations</title><link>https://www.nber.org/papers/w29232</link><description><![CDATA[<b>September 2021</b> <p> Asset prices are a valuable source of information about financial market participants' expectations about key macroeconomic variables. However, the presence of time-varying risk premia requires an adjustment of market prices to obtain the market's rational assessment of future price and policy developments. This paper reviews empirical approaches for recovering market-based expectations. It starts by laying out the two canonical modeling frameworks that form the backbone for estimating risk premia and highlights the proliferation of risk pricing factors that result in a wide range of different asset-price-based expectation measures. It then describes a key methodological innovation to evaluate the empirical plausibility of risk premium estimates and to identify the most accurate market-based expectation measure. The usefulness of this general approach is illustrated for price expectations in the global oil market. Then, the paper provides an overview of the body of empirical evidence for monetary policy and inflation expectations with a special emphasis on market-specific characteristics that complicate the quest for the best possible market-based expectation measure. Finally, it discusses a number of economic applications where market expectations play a key role for evaluating economic models, guiding policy analysis, and deriving shock measures.]]></description><author>Christiane Baumeister</author><guid isPermaLink="true">https://www.nber.org/papers/w29232</guid></item><item><title>How Well Does Bargaining Work in Consumer Markets? A Robust Bounds Approach</title><link>https://www.nber.org/papers/w29202</link><description><![CDATA[<b>August 2021</b> <p> This study provides a structural analysis of detailed, alternating-offer bargaining data from eBay, deriving bounds on buyers and sellers private value distributions using a range of assumptions on behavior. These assumptions range from very weak (assuming only that acceptance and rejection decisions are rational) to less weak (e.g., assuming that bargaining offers are weakly increasing in players' private values). We estimate the bounds and show what they imply for consumer negotiation behavior in theory and practice. For the median product, bargaining ends in impasses in 43% of negotiations even when the buyer values the good more than the seller.]]></description><author>Joachim Freyberger, Bradley Larsen</author><guid isPermaLink="true">https://www.nber.org/papers/w29202</guid></item><item><title>Visualization, Identification, and Estimation in the Linear Panel Event-Study Design</title><link>https://www.nber.org/papers/w29170</link><description><![CDATA[<b>August 2021</b> <p> Linear panel models, and the "event-study plots" that often accompany them, are popular tools for learning about policy effects.  We discuss the construction of event-study plots and suggest ways to make them more informative. We examine the economic content of different possible identifying assumptions. We explore the performance of the corresponding estimators in simulations, highlighting that a given estimator can perform well or poorly depending on the economic environment. An accompanying Stata package, -xtevent-, facilitates adoption of our suggestions.]]></description><author>Simon Freyaldenhoven, Christian Hansen, Jorge Pérez Pérez, Jesse M. Shapiro</author><guid isPermaLink="true">https://www.nber.org/papers/w29170</guid></item><item><title>Do Lenders Still Discriminate? A Robust Approach for Assessing Differences in Menus</title><link>https://www.nber.org/papers/w29142</link><description><![CDATA[<b>August 2021</b> <p> Motivated by the assessment of racial discrimination in mortgage pricing, we introduce a new methodology for comparing the menus of options borrowers face based on their choices. First, we show how standard regression-based approaches for assessing discrimination in the menus context can lead to misleading and contradictory results. Second, we propose a new methodology that is robust these problems based on relatively weak economic assumptions. More specifically, we use pairwise dominance relationships in choices supplemented by restrictions on the range of plausible menus to define (1) a test statistic for equality in menus and (2) a difference in menus (DIM) metric for assessing whether one group of borrowers would prefer to switch to another group's menus. Our statistics are robust to arbitrary heterogeneity in borrower preferences across racial groups, are sharp in terms of identification, and can be efficiently computed using Optimal Transport methods. Third, we devise a new approach for inference on the value of Optimal Transport problems based on directional differentiation. Fourth, we use our methodology to estimate mortgage pricing differentials by race on a novel data set linking 2018--2019 Home Mortgage Disclosure Act (HMDA) data to Optimal Blue rate locks. We find robust evidence for mortgage pricing differentials by race, particularly among Conforming mortgage borrowers who are relatively creditworthy.]]></description><author>David Hao Zhang, Paul S. Willen</author><guid isPermaLink="true">https://www.nber.org/papers/w29142</guid></item><item><title>Exploring Spatial Price Relationships: The Case of African Swine Fever in China</title><link>https://www.nber.org/papers/w29141</link><description><![CDATA[<b>August 2021</b> <p> We use a temporary ban on inter-province shipping of live hogs induced by the 2018 outbreak of African Swine Fever (ASF) in China as a natural experiment to study spatial mechanisms behind the dynamics of market integration. With a unique dataset of weekly provincial hog prices, we employ a novel spatial network model to estimate the strength of price co-movement across provinces pre and post the ban. Results indicate that, in the highly integrated national market prior to the ban, longer geographical distances between two provinces did not weaken the strength of their price linkage. The ban broken down spatial integration. Longer distances became a significant obstacle to spatial price linkage in the post-ban periods, implying faster re-integration of hog prices between proximate provinces than remote ones. The negative effect of distance can be rationalized by the interplay between arbitrage opportunities and imperfect information. Our findings highlight information transparency as a key to market integration post shipping bans used to curb animal pandemics like ASF.]]></description><author>Michael S. Delgado, Meilin Ma, H. Holly Wang</author><guid isPermaLink="true">https://www.nber.org/papers/w29141</guid></item><item><title>Valid t-ratio Inference for IV</title><link>https://www.nber.org/papers/w29124</link><description><![CDATA[<b>August 2021</b> <p> In the single-IV model, researchers commonly rely on t-ratio-based inference, even though the literature has quantified its potentially severe large-sample distortions. Building on the approach for correcting inference of Stock and Yogo (2005), we introduce the tF critical value function, leading to a minimized standard error adjustment factor that is a smooth function of the first-stage F-statistic. Applying the correction to a sample of 61 AER papers leads to a 25 percent increase in standard errors, on average. tF confidence intervals have shorter expected length than those of Anderson and Rubin (1949), whenever both are bounded intervals.]]></description><author>David S. Lee, Justin McCrary, Marcelo J. Moreira, Jack R. Porter</author><guid isPermaLink="true">https://www.nber.org/papers/w29124</guid></item><item><title>Consistent Evidence on Duration Dependence of Price Changes</title><link>https://www.nber.org/papers/w29112</link><description><![CDATA[<b>August 2021</b> <p> We develop an estimator and tests of a discrete time mixed proportional hazard (MPH) model of duration with unobserved heterogeneity. We allow for competing risks, observable characteristics, and censoring, and we use linear GMM, making estimation and inference straightforward. With repeated spell data, our estimator is consistent and robust to the unknown shape of the frailty distribution. We apply our estimator to the duration of price spells in weekly store data from IRI. We find substantial unobserved heterogeneity, accounting for a large fraction of the decrease in the Kaplan-Meier hazard with elapsed duration. Still, we show that the estimated baseline hazard rate is decreasing and a homogeneous firm model can accurately capture the response of the economy to a monetary policy shock even if there is significant strategic complementarity in pricing. Using competing risks and spell-specific observable characteristics, we separately estimate the model for regular and temporary price changes and find that the MPH structure describes regular price changes better than temporary ones.]]></description><author>Fernando E. Alvarez, Katarína Borovičková, Robert Shimer</author><guid isPermaLink="true">https://www.nber.org/papers/w29112</guid></item></channel></rss>